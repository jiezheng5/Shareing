{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "Device name: GeForce GTX 1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brittany/py36_vir2/lib/python3.6/site-packages/torch/cuda/__init__.py:81: UserWarning: \n",
      "    Found GPU1 Quadro K2000 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/brittany/uiuc_mcs/cs410/ClassificationCompetition/data/test.jsonl', '/home/brittany/uiuc_mcs/cs410/ClassificationCompetition/data/train.jsonl']\n"
     ]
    }
   ],
   "source": [
    "files=[]\n",
    "for dirname, _, filenames in os.walk('/home/brittany/uiuc_mcs/cs410/ClassificationCompetition/data/'):\n",
    "    for filename in filenames:\n",
    "        files.append(os.path.join(dirname, filename))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n",
       "      <td>[A minor child deserves privacy and should be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER trying to protest about . Talking ...</td>\n",
       "      <td>[@USER @USER Why is he a loser ? He's just a P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER @USER He makes an insane about of ...</td>\n",
       "      <td>[Donald J . Trump is guilty as charged . The e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER Meanwhile Trump won't even release...</td>\n",
       "      <td>[Jamie Raskin tanked Doug Collins . Collins lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n",
       "      <td>[Man ... y ‚Äô all gone ‚Äú both sides ‚Äù the apoca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>@USER You don't . I have purchased a lot on Am...</td>\n",
       "      <td>[@USER Apologies for the inconvenience you fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>@USER #Emotions you say ü§î never knew that I th...</td>\n",
       "      <td>[@USER ü§î idk tho , I think I ‚Äô m #hungry . But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>@USER @USER @USER You are so right ... \" Yes !...</td>\n",
       "      <td>[@USER @USER @USER Peace to you , and two coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>@USER @USER @USER Another lazy delusional vote...</td>\n",
       "      <td>[Bernie Sanders told Elizabeth Warren in priva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>@USER @USER I hope you know no news outlet fro...</td>\n",
       "      <td>[PDP PROTEST BRAINSTORMING SESSION Deji : We n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                           response  \\\n",
       "0         SARCASM  @USER @USER @USER I don't get this .. obviousl...   \n",
       "1         SARCASM  @USER @USER trying to protest about . Talking ...   \n",
       "2         SARCASM  @USER @USER @USER He makes an insane about of ...   \n",
       "3         SARCASM  @USER @USER Meanwhile Trump won't even release...   \n",
       "4         SARCASM  @USER @USER Pretty Sure the Anti-Lincoln Crowd...   \n",
       "...           ...                                                ...   \n",
       "4995  NOT_SARCASM  @USER You don't . I have purchased a lot on Am...   \n",
       "4996  NOT_SARCASM  @USER #Emotions you say ü§î never knew that I th...   \n",
       "4997  NOT_SARCASM  @USER @USER @USER You are so right ... \" Yes !...   \n",
       "4998  NOT_SARCASM  @USER @USER @USER Another lazy delusional vote...   \n",
       "4999  NOT_SARCASM  @USER @USER I hope you know no news outlet fro...   \n",
       "\n",
       "                                                context  \n",
       "0     [A minor child deserves privacy and should be ...  \n",
       "1     [@USER @USER Why is he a loser ? He's just a P...  \n",
       "2     [Donald J . Trump is guilty as charged . The e...  \n",
       "3     [Jamie Raskin tanked Doug Collins . Collins lo...  \n",
       "4     [Man ... y ‚Äô all gone ‚Äú both sides ‚Äù the apoca...  \n",
       "...                                                 ...  \n",
       "4995  [@USER Apologies for the inconvenience you fac...  \n",
       "4996  [@USER ü§î idk tho , I think I ‚Äô m #hungry . But...  \n",
       "4997  [@USER @USER @USER Peace to you , and two coun...  \n",
       "4998  [Bernie Sanders told Elizabeth Warren in priva...  \n",
       "4999  [PDP PROTEST BRAINSTORMING SESSION Deji : We n...  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train=pd.read_json(files[1], lines=True) #, orient='split')\n",
    "pd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter_1</td>\n",
       "      <td>@USER @USER @USER My 3 year old , that just fi...</td>\n",
       "      <td>[Well now that ‚Äô s problematic AF &lt;URL&gt;, @USER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter_2</td>\n",
       "      <td>@USER @USER How many verifiable lies has he to...</td>\n",
       "      <td>[Last week the Fake News said that a section o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter_3</td>\n",
       "      <td>@USER @USER @USER Maybe Docs just a scrub of a...</td>\n",
       "      <td>[@USER Let ‚Äô s Aplaud Brett When he deserves i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter_4</td>\n",
       "      <td>@USER @USER is just a cover up for the real ha...</td>\n",
       "      <td>[Women generally hate this president . What's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter_5</td>\n",
       "      <td>@USER @USER @USER The irony being that he even...</td>\n",
       "      <td>[Dear media Remoaners , you excitedly sharing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>twitter_1796</td>\n",
       "      <td>@USER @USER @USER is definitely the best out t...</td>\n",
       "      <td>[I have been a business customer of MWeb @USER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>twitter_1797</td>\n",
       "      <td>@USER @USER Ye let her out run wild and infect...</td>\n",
       "      <td>[A woman refuses to have her temperature taken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>twitter_1798</td>\n",
       "      <td>@USER @USER @USER Thanks for that , I would ha...</td>\n",
       "      <td>[The reason big government wants @USER out is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>twitter_1799</td>\n",
       "      <td>@USER @USER @USER Yes also #found this on #new...</td>\n",
       "      <td>[Happy #musicmonday and #thanks for #all your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>twitter_1800</td>\n",
       "      <td>@USER @USER @USER you still need to send the l...</td>\n",
       "      <td>[Not long wrapped on the amazing #January22nd ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                           response  \\\n",
       "0        twitter_1  @USER @USER @USER My 3 year old , that just fi...   \n",
       "1        twitter_2  @USER @USER How many verifiable lies has he to...   \n",
       "2        twitter_3  @USER @USER @USER Maybe Docs just a scrub of a...   \n",
       "3        twitter_4  @USER @USER is just a cover up for the real ha...   \n",
       "4        twitter_5  @USER @USER @USER The irony being that he even...   \n",
       "...            ...                                                ...   \n",
       "1795  twitter_1796  @USER @USER @USER is definitely the best out t...   \n",
       "1796  twitter_1797  @USER @USER Ye let her out run wild and infect...   \n",
       "1797  twitter_1798  @USER @USER @USER Thanks for that , I would ha...   \n",
       "1798  twitter_1799  @USER @USER @USER Yes also #found this on #new...   \n",
       "1799  twitter_1800  @USER @USER @USER you still need to send the l...   \n",
       "\n",
       "                                                context  \n",
       "0     [Well now that ‚Äô s problematic AF <URL>, @USER...  \n",
       "1     [Last week the Fake News said that a section o...  \n",
       "2     [@USER Let ‚Äô s Aplaud Brett When he deserves i...  \n",
       "3     [Women generally hate this president . What's ...  \n",
       "4     [Dear media Remoaners , you excitedly sharing ...  \n",
       "...                                                 ...  \n",
       "1795  [I have been a business customer of MWeb @USER...  \n",
       "1796  [A woman refuses to have her temperature taken...  \n",
       "1797  [The reason big government wants @USER out is ...  \n",
       "1798  [Happy #musicmonday and #thanks for #all your ...  \n",
       "1799  [Not long wrapped on the amazing #January22nd ...  \n",
       "\n",
       "[1800 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test=pd.read_json(files[0], lines=True) #, orient='split')\n",
    "pd_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using only response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "hashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\n",
    "mentions = re.compile(r\"^@\\S+|\\s@\\S+\")\n",
    "urls = re.compile(r\"https?://\\S+\")\n",
    "\n",
    "def process_text(text):\n",
    "  text = hashtags.sub(' hashtag', text)\n",
    "  text = mentions.sub(' entity', text)\n",
    "  return text.strip().lower()\n",
    "  \n",
    "def match_expr(pattern, string):\n",
    "  return not pattern.search(string) == None\n",
    "\n",
    "def get_data_wo_urls(dataset):\n",
    "    link_with_urls = dataset.text.apply(lambda x: match_expr(urls, x))\n",
    "    return dataset[[not e for e in link_with_urls]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>response_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n",
       "      <td>[A minor child deserves privacy and should be ...</td>\n",
       "      <td>entity entity entity i don't get this .. obvio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER trying to protest about . Talking ...</td>\n",
       "      <td>[@USER @USER Why is he a loser ? He's just a P...</td>\n",
       "      <td>entity entity trying to protest about . talkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER @USER He makes an insane about of ...</td>\n",
       "      <td>[Donald J . Trump is guilty as charged . The e...</td>\n",
       "      <td>entity entity entity he makes an insane about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER Meanwhile Trump won't even release...</td>\n",
       "      <td>[Jamie Raskin tanked Doug Collins . Collins lo...</td>\n",
       "      <td>entity entity meanwhile trump won't even relea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n",
       "      <td>[Man ... y ‚Äô all gone ‚Äú both sides ‚Äù the apoca...</td>\n",
       "      <td>entity entity pretty sure the anti-lincoln cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>@USER You don't . I have purchased a lot on Am...</td>\n",
       "      <td>[@USER Apologies for the inconvenience you fac...</td>\n",
       "      <td>entity you don't . i have purchased a lot on a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>@USER #Emotions you say ü§î never knew that I th...</td>\n",
       "      <td>[@USER ü§î idk tho , I think I ‚Äô m #hungry . But...</td>\n",
       "      <td>entity hashtag you say ü§î never knew that i thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>@USER @USER @USER You are so right ... \" Yes !...</td>\n",
       "      <td>[@USER @USER @USER Peace to you , and two coun...</td>\n",
       "      <td>entity entity entity you are so right ... \" ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>@USER @USER @USER Another lazy delusional vote...</td>\n",
       "      <td>[Bernie Sanders told Elizabeth Warren in priva...</td>\n",
       "      <td>entity entity entity another lazy delusional v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>@USER @USER I hope you know no news outlet fro...</td>\n",
       "      <td>[PDP PROTEST BRAINSTORMING SESSION Deji : We n...</td>\n",
       "      <td>entity entity i hope you know no news outlet f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                           response  \\\n",
       "0         SARCASM  @USER @USER @USER I don't get this .. obviousl...   \n",
       "1         SARCASM  @USER @USER trying to protest about . Talking ...   \n",
       "2         SARCASM  @USER @USER @USER He makes an insane about of ...   \n",
       "3         SARCASM  @USER @USER Meanwhile Trump won't even release...   \n",
       "4         SARCASM  @USER @USER Pretty Sure the Anti-Lincoln Crowd...   \n",
       "...           ...                                                ...   \n",
       "4995  NOT_SARCASM  @USER You don't . I have purchased a lot on Am...   \n",
       "4996  NOT_SARCASM  @USER #Emotions you say ü§î never knew that I th...   \n",
       "4997  NOT_SARCASM  @USER @USER @USER You are so right ... \" Yes !...   \n",
       "4998  NOT_SARCASM  @USER @USER @USER Another lazy delusional vote...   \n",
       "4999  NOT_SARCASM  @USER @USER I hope you know no news outlet fro...   \n",
       "\n",
       "                                                context  \\\n",
       "0     [A minor child deserves privacy and should be ...   \n",
       "1     [@USER @USER Why is he a loser ? He's just a P...   \n",
       "2     [Donald J . Trump is guilty as charged . The e...   \n",
       "3     [Jamie Raskin tanked Doug Collins . Collins lo...   \n",
       "4     [Man ... y ‚Äô all gone ‚Äú both sides ‚Äù the apoca...   \n",
       "...                                                 ...   \n",
       "4995  [@USER Apologies for the inconvenience you fac...   \n",
       "4996  [@USER ü§î idk tho , I think I ‚Äô m #hungry . But...   \n",
       "4997  [@USER @USER @USER Peace to you , and two coun...   \n",
       "4998  [Bernie Sanders told Elizabeth Warren in priva...   \n",
       "4999  [PDP PROTEST BRAINSTORMING SESSION Deji : We n...   \n",
       "\n",
       "                                     response_processed  \n",
       "0     entity entity entity i don't get this .. obvio...  \n",
       "1     entity entity trying to protest about . talkin...  \n",
       "2     entity entity entity he makes an insane about ...  \n",
       "3     entity entity meanwhile trump won't even relea...  \n",
       "4     entity entity pretty sure the anti-lincoln cro...  \n",
       "...                                                 ...  \n",
       "4995  entity you don't . i have purchased a lot on a...  \n",
       "4996  entity hashtag you say ü§î never knew that i thi...  \n",
       "4997  entity entity entity you are so right ... \" ye...  \n",
       "4998  entity entity entity another lazy delusional v...  \n",
       "4999  entity entity i hope you know no news outlet f...  \n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train['response_processed']=pd_train.response.apply(process_text)\n",
    "pd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>response_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter_1</td>\n",
       "      <td>@USER @USER @USER My 3 year old , that just fi...</td>\n",
       "      <td>[Well now that ‚Äô s problematic AF &lt;URL&gt;, @USER...</td>\n",
       "      <td>entity entity entity my 3 year old , that just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter_2</td>\n",
       "      <td>@USER @USER How many verifiable lies has he to...</td>\n",
       "      <td>[Last week the Fake News said that a section o...</td>\n",
       "      <td>entity entity how many verifiable lies has he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter_3</td>\n",
       "      <td>@USER @USER @USER Maybe Docs just a scrub of a...</td>\n",
       "      <td>[@USER Let ‚Äô s Aplaud Brett When he deserves i...</td>\n",
       "      <td>entity entity entity maybe docs just a scrub o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter_4</td>\n",
       "      <td>@USER @USER is just a cover up for the real ha...</td>\n",
       "      <td>[Women generally hate this president . What's ...</td>\n",
       "      <td>entity entity is just a cover up for the real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter_5</td>\n",
       "      <td>@USER @USER @USER The irony being that he even...</td>\n",
       "      <td>[Dear media Remoaners , you excitedly sharing ...</td>\n",
       "      <td>entity entity entity the irony being that he e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>twitter_1796</td>\n",
       "      <td>@USER @USER @USER is definitely the best out t...</td>\n",
       "      <td>[I have been a business customer of MWeb @USER...</td>\n",
       "      <td>entity entity entity is definitely the best ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>twitter_1797</td>\n",
       "      <td>@USER @USER Ye let her out run wild and infect...</td>\n",
       "      <td>[A woman refuses to have her temperature taken...</td>\n",
       "      <td>entity entity ye let her out run wild and infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>twitter_1798</td>\n",
       "      <td>@USER @USER @USER Thanks for that , I would ha...</td>\n",
       "      <td>[The reason big government wants @USER out is ...</td>\n",
       "      <td>entity entity entity thanks for that , i would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>twitter_1799</td>\n",
       "      <td>@USER @USER @USER Yes also #found this on #new...</td>\n",
       "      <td>[Happy #musicmonday and #thanks for #all your ...</td>\n",
       "      <td>entity entity entity yes also hashtag this on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>twitter_1800</td>\n",
       "      <td>@USER @USER @USER you still need to send the l...</td>\n",
       "      <td>[Not long wrapped on the amazing #January22nd ...</td>\n",
       "      <td>entity entity entity you still need to send th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                           response  \\\n",
       "0        twitter_1  @USER @USER @USER My 3 year old , that just fi...   \n",
       "1        twitter_2  @USER @USER How many verifiable lies has he to...   \n",
       "2        twitter_3  @USER @USER @USER Maybe Docs just a scrub of a...   \n",
       "3        twitter_4  @USER @USER is just a cover up for the real ha...   \n",
       "4        twitter_5  @USER @USER @USER The irony being that he even...   \n",
       "...            ...                                                ...   \n",
       "1795  twitter_1796  @USER @USER @USER is definitely the best out t...   \n",
       "1796  twitter_1797  @USER @USER Ye let her out run wild and infect...   \n",
       "1797  twitter_1798  @USER @USER @USER Thanks for that , I would ha...   \n",
       "1798  twitter_1799  @USER @USER @USER Yes also #found this on #new...   \n",
       "1799  twitter_1800  @USER @USER @USER you still need to send the l...   \n",
       "\n",
       "                                                context  \\\n",
       "0     [Well now that ‚Äô s problematic AF <URL>, @USER...   \n",
       "1     [Last week the Fake News said that a section o...   \n",
       "2     [@USER Let ‚Äô s Aplaud Brett When he deserves i...   \n",
       "3     [Women generally hate this president . What's ...   \n",
       "4     [Dear media Remoaners , you excitedly sharing ...   \n",
       "...                                                 ...   \n",
       "1795  [I have been a business customer of MWeb @USER...   \n",
       "1796  [A woman refuses to have her temperature taken...   \n",
       "1797  [The reason big government wants @USER out is ...   \n",
       "1798  [Happy #musicmonday and #thanks for #all your ...   \n",
       "1799  [Not long wrapped on the amazing #January22nd ...   \n",
       "\n",
       "                                     response_processed  \n",
       "0     entity entity entity my 3 year old , that just...  \n",
       "1     entity entity how many verifiable lies has he ...  \n",
       "2     entity entity entity maybe docs just a scrub o...  \n",
       "3     entity entity is just a cover up for the real ...  \n",
       "4     entity entity entity the irony being that he e...  \n",
       "...                                                 ...  \n",
       "1795  entity entity entity is definitely the best ou...  \n",
       "1796  entity entity ye let her out run wild and infe...  \n",
       "1797  entity entity entity thanks for that , i would...  \n",
       "1798  entity entity entity yes also hashtag this on ...  \n",
       "1799  entity entity entity you still need to send th...  \n",
       "\n",
       "[1800 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test['response_processed']=pd_test.response.apply(process_text)\n",
    "pd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd_train['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brittany/py36_vir2/lib/python3.6/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/brittany/py36_vir2/lib/python3.6/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entity entity entity i don't get this .. obvio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entity entity trying to protest about . talkin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entity entity entity he makes an insane about ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entity entity meanwhile trump won't even relea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entity entity pretty sure the anti-lincoln cro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>entity you don't . i have purchased a lot on a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>entity hashtag you say ü§î never knew that i thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>entity entity entity you are so right ... \" ye...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>entity entity entity another lazy delusional v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>entity entity i hope you know no news outlet f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     entity entity entity i don't get this .. obvio...      1\n",
       "1     entity entity trying to protest about . talkin...      1\n",
       "2     entity entity entity he makes an insane about ...      1\n",
       "3     entity entity meanwhile trump won't even relea...      1\n",
       "4     entity entity pretty sure the anti-lincoln cro...      1\n",
       "...                                                 ...    ...\n",
       "4995  entity you don't . i have purchased a lot on a...      0\n",
       "4996  entity hashtag you say ü§î never knew that i thi...      0\n",
       "4997  entity entity entity you are so right ... \" ye...      0\n",
       "4998  entity entity entity another lazy delusional v...      0\n",
       "4999  entity entity i hope you know no news outlet f...      0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train_x1=pd_train[['response_processed', 'label']]\n",
    "pd_train_x1.loc[:,'new_label'] = pd_train_x1.label.map({'NOT_SARCASM':0,'SARCASM':1})\n",
    "pd_train_x1=pd_train_x1.drop(['label'],axis=1)\n",
    "pd_train_x1.rename(columns={'response_processed': 'text', 'new_label': 'label'}, inplace=True)\n",
    "#pd_train_x1=pd_train_x1[['label','text']]\n",
    "pd_train_x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brittany/py36_vir2/lib/python3.6/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter_1</td>\n",
       "      <td>entity entity entity my 3 year old , that just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter_2</td>\n",
       "      <td>entity entity how many verifiable lies has he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter_3</td>\n",
       "      <td>entity entity entity maybe docs just a scrub o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter_4</td>\n",
       "      <td>entity entity is just a cover up for the real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter_5</td>\n",
       "      <td>entity entity entity the irony being that he e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>twitter_1796</td>\n",
       "      <td>entity entity entity is definitely the best ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>twitter_1797</td>\n",
       "      <td>entity entity ye let her out run wild and infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>twitter_1798</td>\n",
       "      <td>entity entity entity thanks for that , i would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>twitter_1799</td>\n",
       "      <td>entity entity entity yes also hashtag this on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>twitter_1800</td>\n",
       "      <td>entity entity entity you still need to send th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text\n",
       "0        twitter_1  entity entity entity my 3 year old , that just...\n",
       "1        twitter_2  entity entity how many verifiable lies has he ...\n",
       "2        twitter_3  entity entity entity maybe docs just a scrub o...\n",
       "3        twitter_4  entity entity is just a cover up for the real ...\n",
       "4        twitter_5  entity entity entity the irony being that he e...\n",
       "...            ...                                                ...\n",
       "1795  twitter_1796  entity entity entity is definitely the best ou...\n",
       "1796  twitter_1797  entity entity ye let her out run wild and infe...\n",
       "1797  twitter_1798  entity entity entity thanks for that , i would...\n",
       "1798  twitter_1799  entity entity entity yes also hashtag this on ...\n",
       "1799  twitter_1800  entity entity entity you still need to send th...\n",
       "\n",
       "[1800 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test_x1=pd_test[['id', 'response_processed']]\n",
    "pd_test_x1.rename(columns={'id': 'id', 'response_processed': 'text'}, inplace=True)\n",
    "pd_test_x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 3750\n",
      "VAL size: 250\n",
      "TEST size: 1000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TRAIN_SIZE = 0.75\n",
    "VAL_SIZE = 0.05\n",
    "dataset_count = len(pd_train_x1)\n",
    "\n",
    "df_train_val, df_test = train_test_split(pd_train_x1, test_size=1-TRAIN_SIZE-VAL_SIZE, random_state=42)\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=VAL_SIZE / (VAL_SIZE + TRAIN_SIZE), random_state=42)\n",
    "\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"VAL size:\", len(df_val))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>entity that sounded a bit creepy . now i'm pan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>day thirteen of three hundred and sixty five ....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>entity entity hashtag for life due to high tox...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>entity entity you are a typical killary suppor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>entity entity entity i would like to give you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "212   entity that sounded a bit creepy . now i'm pan...      1\n",
       "3012  day thirteen of three hundred and sixty five ....      0\n",
       "2823  entity entity hashtag for life due to high tox...      0\n",
       "2993  entity entity you are a typical killary suppor...      0\n",
       "128   entity entity entity i would like to give you ...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = get_data_wo_urls(df_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‚Äòdataset‚Äô: File exists\n",
      "dev.tsv  test.tsv  train.tsv\n"
     ]
    }
   ],
   "source": [
    "!mkdir dataset\n",
    "df_train.sample(frac=1.0).reset_index(drop=True).to_csv('dataset/train.tsv', sep='\\t', index=None, header=None)\n",
    "df_val.to_csv('dataset/dev.tsv', sep='\\t', index=None, header=None)\n",
    "df_test.to_csv('dataset/test.tsv', sep='\\t', index=None, header=None)\n",
    "! cd dataset && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in /home/brittany/anaconda3/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (1.33.2)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (0.11.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (3.14.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (0.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (1.18.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (2.4.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.23.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (49.2.0.post20200714)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/brittany/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/brittany/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/brittany/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/brittany/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/brittany/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/brittany/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/brittany/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/brittany/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install tensorflow-gpu==11.1.105\n",
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BertLibrary in /home/brittany/anaconda3/lib/python3.8/site-packages (0.0.4)\n",
      "Requirement already satisfied: numpy in /home/brittany/anaconda3/lib/python3.8/site-packages (from BertLibrary) (1.18.5)\n",
      "Requirement already satisfied: bert-tensorflow in /home/brittany/anaconda3/lib/python3.8/site-packages (1.0.4)\n",
      "Requirement already satisfied: six in /home/brittany/anaconda3/lib/python3.8/site-packages (from bert-tensorflow) (1.15.0)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'BertLibrary' has no attribute 'bert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2387446d6458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install bert-tensorflow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBertLibrary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertFTModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36_vir2/lib/python3.6/site-packages/BertLibrary/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBertLibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBertFEModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertFEModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBertLibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBertFTModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertFTModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36_vir2/lib/python3.6/site-packages/BertLibrary/models/BertFEModel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBertLibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_classifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertLibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mBertModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBertLibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFEProcessor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFEProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36_vir2/lib/python3.6/site-packages/BertLibrary/bert/run_classifier.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mBertLibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertLibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertLibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'BertLibrary' has no attribute 'bert'"
     ]
    }
   ],
   "source": [
    "!pip install BertLibrary\n",
    "from transformers import pipeline\n",
    "!pip install bert-tensorflow\n",
    "from BertLibrary import BertFTModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Uncomment to download \"stopwords\"\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_preprocessing(s):\n",
    "    \"\"\"\n",
    "    - Lowercase the sentence\n",
    "    - Change \"'t\" to \"not\"\n",
    "    - Remove \"@name\"\n",
    "    - Isolate and remove punctuations except \"?\"\n",
    "    - Remove other special characters\n",
    "    - Remove stop words except \"not\" and \"can\"\n",
    "    - Remove trailing whitespace\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "    # Isolate and remove punctuations except '?'\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|‚Ä¢¬´\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertFTModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6d86d73e042d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m ft_model = BertFTModel( model_dir='uncased_L-12_H-768_A-12',\n\u001b[0m\u001b[1;32m      2\u001b[0m                          \u001b[0mckpt_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bert_model.ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0mnum_train_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BertFTModel' is not defined"
     ]
    }
   ],
   "source": [
    "ft_model = BertFTModel( model_dir='uncased_L-12_H-768_A-12',\n",
    "                         ckpt_name=\"bert_model.ckpt\",\n",
    "                         labels=['0','1'],\n",
    "                         lr=1e-05,\n",
    "                         num_train_steps=30000,\n",
    "                         num_warmup_steps=1000,\n",
    "                         ckpt_output_dir='output',\n",
    "                         save_check_steps=1000,\n",
    "                         do_lower_case=False,\n",
    "                         max_seq_len=50,\n",
    "                         batch_size=32,\n",
    "                         )\n",
    "\n",
    "\n",
    "ft_trainer =  ft_model.get_trainer()\n",
    "ft_evaluator = ft_model.get_evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ft_trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0097b480e628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mft_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ft_trainer' is not defined"
     ]
    }
   ],
   "source": [
    "ft_trainer.train_from_file('dataset', 35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ft_evaluator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-35c00227b11b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mft_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output/model.ckpt-35000\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ft_evaluator' is not defined"
     ]
    }
   ],
   "source": [
    "ft_evaluator.evaluate_from_file('dataset', checkpoint=\"output/model.ckpt-35000\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_vir2",
   "language": "python",
   "name": "py36_vir2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
